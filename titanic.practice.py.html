#!/usr/bin/env python
# coding: utf-8

# In[432]:


from sklearn import preprocessing
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import RandomForestRegressor

import warnings
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

get_ipython().run_line_magic('matplotlib', 'inline')


# In[433]:


train = pd.read_csv('/Users/beiyulin/Desktop/Titanic.train.csv')
test  =pd.read_csv('/Users/beiyulin/Desktop/Titanic.test.csv')
submit=pd.read_csv('/Users/beiyulin/Desktop/Titanic.gender_submission.csv')


# In[434]:


train.info()


# In[435]:


test.info()


# In[436]:


train.describe()


# In[437]:


test.describe()


# In[438]:


data =train.append(test)
data


# In[439]:


data.reset_index(inplace=True,drop =True)


# In[440]:


sns.countplot(data['Survived'])


# In[441]:


sns.countplot(data['Pclass'], hue=data['Survived'])


# In[442]:


sns.countplot(data['Sex'],hue =data['Survived'])


# In[443]:


sns.countplot(data['Embarked'],hue =data['Survived'])


# In[444]:


g=sns.FacetGrid(data, col='Survived') 
g.map(sns.distplot,'Age',kde=False)


# In[445]:


g=sns.FacetGrid(data, col='Survived') 
g.map(sns.distplot,'Fare',kde=False)


# In[446]:


g=sns.FacetGrid(data, col='Survived') 
g.map(sns.distplot,'Parch',kde=False)


# In[447]:


g=sns.FacetGrid(data, col='Survived') 
g.map(sns.distplot,'SibSp',kde=False)


# In[448]:


data['Family_Size']=data['Parch']+data['SibSp']


# In[449]:


g=sns.FacetGrid(data, col='Survived') 
g.map(sns.distplot,'Family_Size',kde=False)


# In[450]:


data['Title1']=data['Name'].str.split("," ,expand =True)[1]  #expand是將其資料分割好


# In[451]:


data['Name'].str.split("," ,expand =True).head(3)


# In[452]:


data['Title1'].head(3)


# In[453]:


data['Title1']=data['Title1'].str.split("." ,expand =True)[0]


# In[454]:


data['Title1'].head(3)


# In[455]:


data['Title1'].str.strip().unique()


# In[456]:


pd.crosstab(data['Title1'],data['Sex']).T.style.background_gradient(cmap='summer_r')


# In[457]:


pd.crosstab(data['Title1'],data['Survived']).T.style.background_gradient(cmap='summer_r')


# In[458]:


data.groupby(['Title1'])['Age'].mean()


# In[459]:


data.groupby(['Title1','Pclass'])['Age'].mean()


# In[460]:


#data['Title2'] = data['Title1'].replace('Mlle','Miss')
#data['Title2'] = data['Title1'].replace('Mme','Mrs')
#data['Title2'] = data['Title1'].replace('Ms','Miss')
#data['Title2'] = data['Title1'].replace('Dr','Mr')
#data['Title2'] = data['Title1'].replace('Major','Mr')
#data['Title2'] = data['Title1'].replace('Lady','Mrs')
#data['Title2'] = data['Title1'].replace('the Countess','Mrs')
#data['Title2'] = data['Title1'].replace('Jonkheer','Mr')
#data['Title2'] = data['Title1'].replace('Col','Mr')
#data['Title2'] = data['Title1'].replace('Rev','Mr')
#data['Title2'] = data['Title1'].replace('Capt','Mr')
#data['Title2'] = data['Title1'].replace('Sir','Mr')
#data['Title2'] = data['Title1'].replace('Don','Mr')
#data['Title2'] = data['Title1'].replace('Dona','Mrs')


# In[461]:


#data['Title2'] = data['Title1'].replace(["Mlle","Mme","Ms","Dr","Major","Lady","the Countess","Jonkheer","Col","Rev","Capt","Sir","Don","Dona"],
#["Miss","Mrs","Miss","Mr","Mr","Mrs","Mrs","Mr","Mr","Mr","Mr","Mr","Mr","Mrs"])


# In[468]:


data['Title2'] = data['Title1'].str.strip().replace(['Mlle','Mme','Ms','Dr','Major','Lady','the Countess','Jonkheer','Col','Rev','Capt','Sir','Don','Dona'],
         ['Miss','Mrs','Miss','Mr','Mr','Mrs','Mrs','Mr','Mr','Mr','Mr','Mr','Mr','Mrs'])


# In[472]:


data['Title2'].unique()


# In[473]:


pd.crosstab(data['Title2'],data['Sex']).T.style.background_gradient(cmap='summer_r')


# In[474]:


pd.crosstab(data['Title2'],data['Survived']).T.style.background_gradient(cmap='summer_r')


# In[475]:


data['Ticket_info'] = data['Ticket'].apply(lambda x : x.replace(".","").replace("/","").strip().split(' ')[0] if not x.isdigit() else 'X')


# In[476]:


data['Ticket_info'].unique()


# In[477]:


data['Embarked']= data['Embarked'].fillna('s')


# In[478]:


data['Fare']=data['Fare'].fillna(data['Fare'].mean())


# In[481]:


data['Cabin'].head(10)


# In[487]:


data['Cabin'] = data['Cabin'].apply(lambda x : str(x)[0] if not pd.isnull(x) else 'NoCabin')


# In[488]:


data['Cabin'].unique()


# In[489]:


sns.countplot(data['Cabin'],hue =data['Survived'])


# In[490]:


data['Sex']= data['Sex'].astype('category').cat.codes
data['Embarked']=data['Embarked'].astype('category').cat.codes
data['Pclass']=data['Pclass'].astype('category').cat.codes
data['Title1']=data['Title1'].astype('category').cat.codes
data['Title2']=data['Title2'].astype('category').cat.codes
data['Cabin']=data['Cabin'].astype('category').cat.codes
data['Ticket_info']=data['Ticket_info'].astype('category').cat.codes


# In[491]:


dataAgeNull=data[data['Age'].isnull()]
dataAgeNotNull=data[data['Age'].notnull()]
remove_outlier = dataAgeNotNull[(np.abs(dataAgeNotNull["Fare"]-dataAgeNotNull["Fare"].mean())>(4*dataAgeNotNull["Fare"].std()))|
                      (np.abs(dataAgeNotNull["Family_Size"]-dataAgeNotNull["Family_Size"].mean())>(4*dataAgeNotNull["Family_Size"].std()))                     
                     ]
rfModel_age = RandomForestRegressor(n_estimators=2000,random_state=42)
ageColumns = ['Embarked', 'Fare', 'Pclass', 'Sex', 'Family_Size', 'Title1', 'Title2','Cabin','Ticket_info']
rfModel_age.fit(remove_outlier[ageColumns], remove_outlier["Age"])

ageNullValues = rfModel_age.predict(X= dataAgeNull[ageColumns])
dataAgeNull.loc[:,"Age"] = ageNullValues
data = dataAgeNull.append(dataAgeNotNull)
data.reset_index(inplace=True, drop=True)


# In[496]:


dataTrain = data[pd.notnull(data['Survived'])].sort_values(by=["PassengerId"])
dataTest = data[pd.notnull(data['Survived'])].sort_values(by=["PassengerId"])


# In[497]:


dataTrain.columns


# In[498]:


dataTrain = dataTrain[['Survived', 'Age', 'Embarked', 'Fare',  'Pclass', 'Sex', 'Family_Size', 'Title2','Ticket_info','Cabin']]
dataTest = dataTest[['Age', 'Embarked', 'Fare', 'Pclass', 'Sex', 'Family_Size', 'Title2','Ticket_info','Cabin']]


# In[499]:


dataTrain


# In[500]:


from sklearn.ensemble import RandomForestClassifier
 
rf = RandomForestClassifier(criterion='gini', 
                             n_estimators=1000,
                             min_samples_split=12,
                             min_samples_leaf=1,
                             oob_score=True,
                             random_state=1,
                             n_jobs=-1) 

rf.fit(dataTrain.iloc[:, 1:], dataTrain.iloc[:, 0])
print("%.4f" % rf.oob_score_)


# In[501]:


pd.concat((pd.DataFrame(dataTrain.iloc[:, 1:].columns, columns = ['variable']), 
           pd.DataFrame(rf.feature_importances_, columns = ['importance'])), 
          axis = 1).sort_values(by='importance', ascending = False)[:20]


# In[504]:


rf_res =  rf.predict(dataTest)
submit['Survived'] = rf_res
submit['Survived'] = submit['Survived'].astype(int)
submit.to_csv('submit.csv', index= False)


# In[505]:


submit


# In[ ]:




